
---
title: "dplyr包讲解_处理数据框"
author: "lxh"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
---



# 导言



dplyr 实现的是 SQL 也能做到的事，那掌握这个R语言函数包有什么意义？

* 掌握在R语言环境中进行数据预处理能力，我们并不总是在SQL将数据处理到最终直接使用前的格式

* 利用R语言编程环境，通过变量、循环和控制等形式便捷处理数据表；SQL语言，对于分析师来说是查询工具，对工程师才是编程语言

* 直接利用R语言中的统计分析函数及其他扩展包函数来处理数据


```{r, eval=FALSE, echo=FALSE}
# 5/60
```

```{r}
# 载入 dplyr 包
library("dplyr")
# 查看包作者撰写的帮助文档
browseVignettes(package = "dplyr")
# cases, pollution, storms 数据集在此包中
library("EDAWR") 
library("tidyr")
```



# 基本语法

```{r}
# 将数据框修改为 tbl_df 类型，可以使用 dplyr 特性
iris_df <- tbl_df(iris)

# 原数据框的类有三个值，"tbl_df", "tbl", "data.frame"；在 tbl_df 类上就会有特别的操作，但保留了 data.frame 类，原来对数据框的操作都会保持不变
class(iris_df)

# 在 tbl_df 类下，直接显示数据框，就只会显示前10行记录，且显示的字段会根据当前屏幕宽度适应，超出的字段会简要显示
iris_df

# 显示数据字段的基本类型和前几个数值，和 str() 函数类似
glimpse(iris_df)

```

```{r}
# 管道符号(Piping) %>% 操作，将左边的对象传递给右边函数作为第一个参数对象
# x %>% f(y) 等价于 f(x,y)

iris %>%
  group_by(Species) %>%
  summarise(avg = mean(Sepal.Width)) %>%
  arrange(avg)

```

```{r, eval=FALSE, echo=FALSE}
# 15/60
```

# tidyr

```{r}


# 参数 key 和 value 就是要使其gather的字段和值
# 后面就是需要gather的字段，如果没有就是全部，如果有就按 select 方式筛选


cases
gather(cases, key = "year", value = "n", 2:4)
# 排除某个字段
gather(cases, key = "year", value = "n", -country)

# case stduy 导入分天目标数值

# 参数 key 和 value 就是要使其 spread 的字段和值
# key 的名称就变为扩展后字段的名称
pollution
spread(pollution, key = size, value = amount)

# separate 的参数 sep 是拆分规则，默认会使用一些基本的符号拆分  "[^[:alnum:]]+" ，需要的话可以自定义
storms
s_x <- separate(storms, col = date, into = c("y", "m", "d"))
s_x 

# unite 是 separate 的反函数，逻辑和参数基本相同
unite(s_x, col = "date", c(y, m, d), sep = "-")
```

```{r, eval=FALSE, echo=FALSE}
# 25/60
```


```{r}
# 直接创建 tbl_df 对象
data_frame(a = 1:3, b = 4:6) 
# 与data.frame 相似 
data.frame(a = 1:3, b = 4:6)

# 排序，与SQL相似
arrange(mtcars, mpg)
# 多个字段联合排序
arrange(mtcars, mpg, wt)
# 倒序
arrange(mtcars, desc(mpg), wt)

# 直接重命名某个字段
x_s <- storms
names(x_s)
x_s <- rename(x_s, date_id = date)
names(x_s)


```

```{r, eval=FALSE, echo=FALSE}
# 30/60
```

# 行列筛选，记录和字段筛选，观测和变量筛选



行列筛选拆分为两类，行筛选和列筛选

```{r}
# 行筛选主要使用 filter() 函数，顾名思义就是“过滤”，在SQL中就是 where 条件
# 过滤的条件使用逻辑表达式
filter(iris, Sepal.Length > 7)

# 筛除出数据库中不同的记录（也就是排除重复记录）
distinct(iris)



# 按比例随机筛选记录，可以控制是否有回放抽样，可以指定权重
sample_frac(iris, size = 0.5, replace = FALSE)

# 按数量随机筛选记录，可以控制是否有回放抽样，可以指定权重
sample_n(iris, size = 10, replace = TRUE)

# 按行位置筛选，“切片”，相当于SQL中的 rownum 
slice(iris, 10:15)

# 筛选出某个字段排序结果的前面N行记录
# 返回的结果还是保持原始的排序（结果并未排序），需要排序可使用 arrange() 函数
top_n(iris, n = 5, wt = Sepal.Length)
top_n(storms, n = 3, wt = wind)
top_n(storms, n = 4, wt = pressure)
```

```{r}

storms

# 筛选数据框的字段，直接用名称
select(storms, wind, pressure)

# 正在匹配所需变量
select(storms, matches("s"))
select(storms, matches("^s"))
select(storms, matches("e$"))
select(storms, matches(".+s.+"))

# 筛选两个变量之间的所有变量，可以通过名字选定范围，当然也可以用序号
select(storms, wind:date)
select(storms, 2:4)

# 排除某个变量，使用符号
select(storms, -pressure)
select(storms, -(1:2))
select(storms, -c(pressure, date))
```

```{r, eval=FALSE, echo=FALSE}
# 40/60
```

# 汇总

```{r}
# 对列使用汇总函数（只有一行结果），可以用多个不同的汇总函数
summarise(storms, avg_wind = mean(wind))
summarise(storms, avg_wind = mean(wind), max_pressure = max(pressure))

# 对每列使用汇总函数，汇总函数是相同的
summarise_each(iris, funs(mean))
# 汇总函数后面，可以可以筛选哪些变量参与计算，用法和 select() 一样
summarise_each(storms, funs(mean), vars = -c(storm,date))

# 所谓的汇总函数(summarise functions)，就是对一个向量进行运算，返回单个值
# dplyr中定义了一个常用的汇总函数
summarise_each(storms, funs(first), vars = -c(storm,date))
```

# 变形 
```{r}
# 示例数据集，法德美案件数量
cases
# 在原有单个或多个变量上应用函数（表达式）计算新结果生成新变量，不会删除原变量
mutate(cases, total = 2011 + 2012 + 2013)

# transmute
transmute(cases, total = 2011 + 2012 + 2013)

# 应用在mutate_each上的函数叫 window function
# 在向量上做运算后，返回相同长度的向量
# cumsum() 是累积求和函数
# 无论是 summarize function 还是 windows function，
# 都可以是系统函数，其他包中的函数，也可以是自定义函数
# summarize function 作用在向量上之后，返回一个值
# windows function 作用在向量上之后，返回相同长度的向量
mutate_each(cases, funs(cumsum), -country)

mutate_each(cases, funs(percent_rank), -country)

# case stduy
```

```{r, eval=FALSE, echo=FALSE}
# 50/60
```

# 分组
```{r}
# group_by 应用在数据框上，可指定分组信息，指定分组字段，可使用多个字段分组
group_by(iris, Species)
group_by(mtcars, cyl, gear)
# 分组之后数据框的值没有改变，但分组信息存在这个对象中了
# 分组之后原数据框即使不是tbl_df格式的，也会被转化为tbl_df
# 组分之后增加了 grouped_df 这个类
# 更多信息可以通过attributes
# 有了这个分组信息，后续的函数操作就可直接使用了，特别是汇总函数
class(group_by(iris, Species))
attributes(group_by(mtcars, cyl, gear))

# 结合 %>% 管道操作符，分组汇总就很方便
iris %>% group_by(Species) %>% summarise_each(funs(mean))
iris %>% group_by(Species) %>% summarise(SL_avg = mean(Sepal.Length))

# 取消分组信息
g_iris <- iris %>% group_by(Species)
g_iris
ungroup(g_iris)

```

# 数据框连接(表连接)
```{r}
a <- data_frame(x1 = c("A","B","C"), x2 = 1:3)
b <- data_frame(x1 = c("A","B","D"), x3 = c("T", "F", "T"))
a
b
# mutating joins 
# 与SQL中的join用法基本一致
inner_join(a, b, by = "x1")
left_join(a, b, by = "x1")
right_join(a, b, by = "x1")
full_join(a, b, by = "x1")

# filtering joins 
# 只显示a，条件是能匹配都b的情况
semi_join(a, b, by = "x1")

# 只显示a，条件是匹配不到b的情况
anti_join(a, b, by = "x1")
```

```{r, eval=FALSE, echo=FALSE}
# 60/60
```

